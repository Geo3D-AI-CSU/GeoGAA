"""
ç»“æœåˆ†æå’Œå¯è§†åŒ–è„šæœ¬
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import os
import re


def parse_training_log(log_file):
    """
    è§£æè®­ç»ƒæ—¥å¿—ï¼Œæå–å…³é”®æŒ‡æ ‡

    è¿”å›:
    - metrics_df: DataFrameåŒ…å«æ¯ä¸ªepochçš„æŒ‡æ ‡
    """
    if not os.path.exists(log_file):
        print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return None

    data = {
        'epoch': [],
        'train_level_loss': [],
        'train_grad_loss': [],
        'train_rock_loss': [],
        'train_strat_loss': [],
        'train_rmse': [],
        'train_r2': [],
        'train_acc': [],
        'test_level_loss': [],
        'test_grad_loss': [],
        'test_rock_loss': [],
        'test_strat_loss': [],
        'test_rmse': [],
        'test_r2': [],
        'test_acc': [],
        'test_acc_corrected': []
    }

    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    current_epoch = None

    for i, line in enumerate(lines):
        # æå–epoch
        if 'Epoch' in line and '/' in line:
            try:
                epoch = int(line.split('Epoch')[1].split('/')[0].strip())
                current_epoch = epoch
            except:
                continue

        # æå–è®­ç»ƒæŒ‡æ ‡
        if '[TRAIN]' in line and current_epoch:
            try:
                data['epoch'].append(current_epoch)

                # æå–å„é¡¹æŸå¤±
                level = float(re.search(r'Level: ([\d.]+)', line).group(1))
                grad = float(re.search(r'Grad: ([\d.]+)', line).group(1))
                rock = float(re.search(r'Rock: ([\d.]+)', line).group(1))

                data['train_level_loss'].append(level)
                data['train_grad_loss'].append(grad)
                data['train_rock_loss'].append(rock)

                # åœ°å±‚çº¦æŸæŸå¤±ï¼ˆå¦‚æœæœ‰ï¼‰
                if 'Strat:' in line:
                    strat = float(re.search(r'Strat: ([\d.]+)', line).group(1))
                    data['train_strat_loss'].append(strat)
                else:
                    data['train_strat_loss'].append(0.0)

                # RMSE, R^2, Acc
                rmse = float(re.search(r'RMSE: ([\d.]+)', line).group(1))
                r2 = float(re.search(r'R\^2: ([\d.]+)', line).group(1))
                acc = float(re.search(r'Acc: ([\d.]+)', line).group(1))

                data['train_rmse'].append(rmse)
                data['train_r2'].append(r2)
                data['train_acc'].append(acc)
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œç§»é™¤å½“å‰epoch
                if data['epoch'] and data['epoch'][-1] == current_epoch:
                    for key in data:
                        if data[key] and len(data[key]) > 0:
                            data[key].pop()

        # æå–æµ‹è¯•æŒ‡æ ‡
        if '[TEST]' in line and current_epoch:
            try:
                level = float(re.search(r'Level: ([\d.]+)', line).group(1))
                grad = float(re.search(r'Grad: ([\d.]+)', line).group(1))
                rock = float(re.search(r'Rock: ([\d.]+)', line).group(1))

                data['test_level_loss'].append(level)
                data['test_grad_loss'].append(grad)
                data['test_rock_loss'].append(rock)

                if 'Strat:' in line:
                    strat = float(re.search(r'Strat: ([\d.]+)', line).group(1))
                    data['test_strat_loss'].append(strat)
                else:
                    data['test_strat_loss'].append(0.0)

                rmse = float(re.search(r'RMSE: ([\d.]+)', line).group(1))
                r2 = float(re.search(r'R\^2: ([\d.]+)', line).group(1))
                acc = float(re.search(r'Acc: ([\d.]+)', line).group(1))

                data['test_rmse'].append(rmse)
                data['test_r2'].append(r2)
                data['test_acc'].append(acc)

                # ä¿®æ­£åçš„ç²¾åº¦
                if 'Acc_Corrected:' in line:
                    acc_corr = float(re.search(r'Acc_Corrected: ([\d.]+)', line).group(1))
                    data['test_acc_corrected'].append(acc_corr)
                else:
                    data['test_acc_corrected'].append(acc)
            except:
                pass

    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    return df


def plot_training_curves(metrics_df, save_dir='.'):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    """
    if metrics_df is None or len(metrics_df) == 0:
        print("âš ï¸  æ²¡æœ‰æ•°æ®å¯ç»˜åˆ¶")
        return

    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Training Curves', fontsize=16, fontweight='bold')

    # 1. æŸå¤±æ›²çº¿
    ax = axes[0, 0]
    ax.plot(metrics_df['epoch'], metrics_df['train_level_loss'],
            label='Train Level', marker='o', markersize=3)
    ax.plot(metrics_df['epoch'], metrics_df['test_level_loss'],
            label='Test Level', marker='s', markersize=3)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Level Loss')
    ax.set_title('Level Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 2. æ¢¯åº¦æŸå¤±
    ax = axes[0, 1]
    ax.plot(metrics_df['epoch'], metrics_df['train_grad_loss'],
            label='Train Gradient', marker='o', markersize=3)
    ax.plot(metrics_df['epoch'], metrics_df['test_grad_loss'],
            label='Test Gradient', marker='s', markersize=3)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Gradient Loss')
    ax.set_title('Gradient Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 3. å²©æ€§æŸå¤±
    ax = axes[0, 2]
    ax.plot(metrics_df['epoch'], metrics_df['train_rock_loss'],
            label='Train Rock', marker='o', markersize=3)
    ax.plot(metrics_df['epoch'], metrics_df['test_rock_loss'],
            label='Test Rock', marker='s', markersize=3)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Rock Loss')
    ax.set_title('Rock (Focal) Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 4. åœ°å±‚çº¦æŸæŸå¤±
    ax = axes[1, 0]
    if 'train_strat_loss' in metrics_df.columns:
        ax.plot(metrics_df['epoch'], metrics_df['train_strat_loss'],
                label='Train Strat', marker='o', markersize=3)
        ax.plot(metrics_df['epoch'], metrics_df['test_strat_loss'],
                label='Test Strat', marker='s', markersize=3)
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Stratigraphic Loss')
        ax.set_title('Stratigraphic Constraint Loss')
        ax.legend()
        ax.grid(True, alpha=0.3)

    # 5. RMSE
    ax = axes[1, 1]
    ax.plot(metrics_df['epoch'], metrics_df['train_rmse'],
            label='Train RMSE', marker='o', markersize=3)
    ax.plot(metrics_df['epoch'], metrics_df['test_rmse'],
            label='Test RMSE', marker='s', markersize=3)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('RMSE')
    ax.set_title('RMSE')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 6. å²©æ€§åˆ†ç±»ç²¾åº¦
    ax = axes[1, 2]
    ax.plot(metrics_df['epoch'], metrics_df['train_acc'],
            label='Train Acc', marker='o', markersize=3)
    ax.plot(metrics_df['epoch'], metrics_df['test_acc'],
            label='Test Acc (Original)', marker='s', markersize=3)

    if 'test_acc_corrected' in metrics_df.columns:
        ax.plot(metrics_df['epoch'], metrics_df['test_acc_corrected'],
                label='Test Acc (Corrected)', marker='^', markersize=3, linewidth=2)

    # æ·»åŠ 91%ç›®æ ‡çº¿
    ax.axhline(y=0.91, color='r', linestyle='--', linewidth=2,
               label='Target (91%)', alpha=0.7)

    ax.set_xlabel('Epoch')
    ax.set_ylabel('Accuracy')
    ax.set_title('Rock Unit Classification Accuracy')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0.5, 1.0])

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    save_path = os.path.join(save_dir, 'training_curves.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")

    plt.show()


def plot_confusion_matrix_from_log(log_file, save_dir='.'):
    """
    ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–å¹¶ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    """
    if not os.path.exists(log_file):
        print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return

    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æå–ä¿®æ­£åçš„æ··æ·†çŸ©é˜µ
    if 'Corrected Confusion Matrix:' in content:
        cm_text = content.split('Corrected Confusion Matrix:')[1].split('\n\n')[0]
        matrix_type = 'Corrected'
    elif 'Original Confusion Matrix:' in content:
        cm_text = content.split('Original Confusion Matrix:')[1].split('\n\n')[0]
        matrix_type = 'Original'
    else:
        print("âš ï¸  æ—¥å¿—ä¸­æœªæ‰¾åˆ°æ··æ·†çŸ©é˜µ")
        return

    # è§£æçŸ©é˜µ
    try:
        lines = [line.strip() for line in cm_text.strip().split('\n') if line.strip()]
        cm = []
        for line in lines:
            if line.startswith('[') and line.endswith(']'):
                row = [int(x) for x in line.strip('[]').split()]
                cm.append(row)

        cm = np.array(cm)

        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        plt.figure(figsize=(12, 10))

        # è®¡ç®—æ¯è¡Œçš„å‡†ç¡®ç‡
        row_sums = cm.sum(axis=1, keepdims=True)
        cm_normalized = cm / row_sums

        # ç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',
                    cbar_kws={'label': 'Accuracy'})

        plt.xlabel('Predicted Rock Unit', fontsize=12)
        plt.ylabel('True Rock Unit', fontsize=12)
        plt.title(f'{matrix_type} Confusion Matrix (Normalized by Row)',
                  fontsize=14, fontweight='bold')

        # æ·»åŠ ç±»åˆ«æ ‡ç­¾
        rock_units = list(range(1, cm.shape[0] + 1))
        plt.xticks(np.arange(len(rock_units)) + 0.5, rock_units)
        plt.yticks(np.arange(len(rock_units)) + 0.5, rock_units)

        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(save_dir, f'confusion_matrix_{matrix_type.lower()}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")

        plt.show()

        # è®¡ç®—å¹¶æ‰“å°å„ç±»åˆ«ç²¾åº¦
        print(f"\nå„å²©æ€§ç±»åˆ«ç²¾åº¦ ({matrix_type}):")
        for i, rock_unit in enumerate(rock_units):
            if row_sums[i] > 0:
                acc = cm[i, i] / row_sums[i]
                print(f"  Rock Unit {rock_unit:2d}: {acc:.2%} ({cm[i, i]}/{int(row_sums[i])})")

        overall_acc = np.trace(cm) / cm.sum()
        print(f"\næ€»ä½“ç²¾åº¦: {overall_acc:.4f} ({overall_acc:.2%})")

    except Exception as e:
        print(f"âŒ è§£ææ··æ·†çŸ©é˜µå¤±è´¥: {e}")


def compare_experiments(result_dirs, labels=None):
    """
    æ¯”è¾ƒå¤šä¸ªå®éªŒç»“æœ

    å‚æ•°:
    - result_dirs: ç»“æœç›®å½•åˆ—è¡¨
    - labels: å®éªŒæ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    """
    if labels is None:
        labels = [f"Exp{i + 1}" for i in range(len(result_dirs))]

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # 1. æµ‹è¯•ç²¾åº¦å¯¹æ¯”
    ax = axes[0]

    for i, (result_dir, label) in enumerate(zip(result_dirs, labels)):
        log_file = os.path.join(result_dir, 'training_log_with_constraints.txt')
        if not os.path.exists(log_file):
            log_file = os.path.join(result_dir, 'multitask_training_log_v1.txt')

        if os.path.exists(log_file):
            df = parse_training_log(log_file)
            if df is not None and len(df) > 0:
                if 'test_acc_corrected' in df.columns:
                    ax.plot(df['epoch'], df['test_acc_corrected'],
                            label=label, marker='o', markersize=3)
                else:
                    ax.plot(df['epoch'], df['test_acc'],
                            label=label, marker='o', markersize=3)

    ax.axhline(y=0.91, color='r', linestyle='--', linewidth=2,
               label='Target (91%)', alpha=0.7)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Test Accuracy')
    ax.set_title('Test Accuracy Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0.7, 1.0])

    # 2. æœ€ç»ˆç²¾åº¦æ¡å½¢å›¾
    ax = axes[1]

    final_accs = []
    for result_dir in result_dirs:
        log_file = os.path.join(result_dir, 'training_log_with_constraints.txt')
        if not os.path.exists(log_file):
            log_file = os.path.join(result_dir, 'multitask_training_log_v1.txt')

        if os.path.exists(log_file):
            df = parse_training_log(log_file)
            if df is not None and len(df) > 0:
                if 'test_acc_corrected' in df.columns:
                    final_accs.append(df['test_acc_corrected'].max())
                else:
                    final_accs.append(df['test_acc'].max())
            else:
                final_accs.append(0)
        else:
            final_accs.append(0)

    colors = ['green' if acc >= 0.91 else 'orange' for acc in final_accs]
    bars = ax.bar(labels, final_accs, color=colors, alpha=0.7)
    ax.axhline(y=0.91, color='r', linestyle='--', linewidth=2, label='Target')
    ax.set_ylabel('Best Test Accuracy')
    ax.set_title('Final Accuracy Comparison')
    ax.set_ylim([0.7, 1.0])
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')

    # åœ¨æŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼
    for bar, acc in zip(bars, final_accs):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2., height,
                f'{acc:.3f}',
                ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.savefig('experiment_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ… å®éªŒå¯¹æ¯”å›¾å·²ä¿å­˜: experiment_comparison.png")
    plt.show()


def analyze_result(result_dir):
    """
    å…¨é¢åˆ†æå•ä¸ªå®éªŒç»“æœ
    """
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Š åˆ†æå®éªŒç»“æœ: {result_dir}")
    print(f"{'=' * 80}\n")

    # 1. è§£æè®­ç»ƒæ—¥å¿—
    log_file = os.path.join(result_dir, 'training_log_with_constraints.txt')
    if not os.path.exists(log_file):
        log_file = os.path.join(result_dir, 'multitask_training_log_v1.txt')

    if os.path.exists(log_file):
        print("âœ… æ‰¾åˆ°è®­ç»ƒæ—¥å¿—")
        df = parse_training_log(log_file)

        if df is not None and len(df) > 0:
            print(f"   è®­ç»ƒäº† {len(df)} ä¸ªè®°å½•ç‚¹")

            # æ‰“å°æœ€ç»ˆç»“æœ
            if 'test_acc_corrected' in df.columns:
                best_acc = df['test_acc_corrected'].max()
                best_epoch = df.loc[df['test_acc_corrected'].idxmax(), 'epoch']
            else:
                best_acc = df['test_acc'].max()
                best_epoch = df.loc[df['test_acc'].idxmax(), 'epoch']

            print(f"   æœ€ä½³ç²¾åº¦: {best_acc:.4f} (Epoch {int(best_epoch)})")

            if best_acc >= 0.91:
                print("   ğŸ‰ è¾¾åˆ°ç›®æ ‡ç²¾åº¦ (>91%)!")
            else:
                diff = 0.91 - best_acc
                print(f"   âš ï¸  è·ç¦»ç›®æ ‡è¿˜å·® {diff:.4f} ({diff * 100:.2f}%)")

            # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
            plot_training_curves(df, save_dir=result_dir)

        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        plot_confusion_matrix_from_log(log_file, save_dir=result_dir)

    else:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ç»“æœåˆ†æè„šæœ¬')
    parser.add_argument('--result_dir', type=str, default=None,
                        help='ç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--compare', nargs='+', default=None,
                        help='æ¯”è¾ƒå¤šä¸ªå®éªŒç›®å½•')
    parser.add_argument('--labels', nargs='+', default=None,
                        help='å®éªŒæ ‡ç­¾ï¼ˆä¸--compareé…åˆä½¿ç”¨ï¼‰')

    args = parser.parse_args()

    if args.compare:
        # æ¯”è¾ƒæ¨¡å¼
        compare_experiments(args.compare, args.labels)
    elif args.result_dir:
        # å•ä¸ªå®éªŒåˆ†æ
        analyze_result(args.result_dir)
    else:
        # é»˜è®¤ï¼šåˆ†ææœ€æ–°çš„ç»“æœ
        print("è¯·æŒ‡å®š --result_dir æˆ– --compare å‚æ•°")
        print("\nç¤ºä¾‹:")
        print("  python analyze_results.py --result_dir ./Result/MultiTask_Constrained_Test")
        print("  python analyze_results.py --compare ./Result/Exp1 ./Result/Exp2 --labels Original Improved")